{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MedGemma 1.5 Capability Testing\n",
    "\n",
    "**Date:** January 13-14, 2026\n",
    "**Phase:** Phase 1 - Data Exploration\n",
    "**Objective:** Test MedGemma 1.5 4B capabilities and document strengths/limitations\n",
    "\n",
    "## MedGemma 1.5 Overview\n",
    "\n",
    "MedGemma 1.5 4B is Google's latest open multimodal medical AI model with:\n",
    "- **High-dimensional imaging:** 3D CT and MRI interpretation\n",
    "- **Longitudinal analysis:** Time-series medical imaging\n",
    "- **Anatomical localization:** Bounding box detection\n",
    "- **Clinical text:** Medical reasoning and document understanding\n",
    "- **Small enough to run offline:** 4B parameters\n",
    "\n",
    "**Model:** `google/medgemma-1.5-4b-it` on Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers accelerate torch pillow pydicom nibabel -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load MedGemma 1.5 Model\n",
    "\n",
    "Loading the model from Hugging Face. This may take a few minutes on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/medgemma-1.5-4b-it\"\n",
    "\n",
    "print(f\"Loading MedGemma 1.5 from {MODEL_NAME}...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Load model\n",
    "# Use device_map=\"auto\" to automatically use GPU if available\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    ")\n",
    "\n",
    "load_time = time.time() - start_time\n",
    "print(f\"✓ Model loaded in {load_time:.2f} seconds\")\n",
    "print(f\"Model size: {sum(p.numel() for p in model.parameters()) / 1e9:.2f}B parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Clinical Text Understanding\n",
    "\n",
    "Testing MedGemma's ability to understand and reason about medical text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_medical_text(prompt, max_length=512):\n",
    "    \"\"\"Test MedGemma on medical text prompts\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    return response, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Clinical Case Interpretation\n",
    "prompt1 = \"\"\"Patient: 65-year-old male with hypertension and diabetes.\n",
    "Chief Complaint: Shortness of breath and chest pain for 2 days.\n",
    "Vital Signs: BP 160/95, HR 105, RR 22, O2 Sat 89% on room air.\n",
    "Labs: Troponin elevated at 0.8 ng/mL (normal <0.04), BNP 450 pg/mL.\n",
    "\n",
    "Question: What is the most likely diagnosis and recommended immediate management?\n",
    "\"\"\"\n",
    "\n",
    "response1, time1 = test_medical_text(prompt1)\n",
    "print(f\"Response (generated in {time1:.2f}s):\")\n",
    "print(response1)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Lab Report Interpretation\n",
    "prompt2 = \"\"\"Lab Results:\n",
    "- WBC: 15,000/μL (elevated)\n",
    "- Neutrophils: 85% (elevated)\n",
    "- Hemoglobin: 10.2 g/dL (low)\n",
    "- Platelets: 450,000/μL (elevated)\n",
    "- CRP: 12 mg/dL (elevated)\n",
    "\n",
    "Question: Interpret these lab findings and suggest possible diagnoses.\n",
    "\"\"\"\n",
    "\n",
    "response2, time2 = test_medical_text(prompt2)\n",
    "print(f\"Response (generated in {time2:.2f}s):\")\n",
    "print(response2)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Medical Q&A\n",
    "prompt3 = \"\"\"Question: What are the key differences between Type 1 and Type 2 diabetes mellitus in terms of:\n",
    "1. Pathophysiology\n",
    "2. Age of onset\n",
    "3. Treatment approach\n",
    "\"\"\"\n",
    "\n",
    "response3, time3 = test_medical_text(prompt3)\n",
    "print(f\"Response (generated in {time3:.2f}s):\")\n",
    "print(response3)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Metrics\n",
    "\n",
    "Documenting inference speed and resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average inference time\n",
    "avg_time = (time1 + time2 + time3) / 3\n",
    "print(f\"Average inference time: {avg_time:.2f} seconds\")\n",
    "print(f\"Range: {min(time1, time2, time3):.2f}s - {max(time1, time2, time3):.2f}s\")\n",
    "\n",
    "# Memory usage (if on GPU)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nGPU Memory Usage:\")\n",
    "    print(f\"Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    print(f\"Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Medical Image Interpretation (If Image Support Available)\n",
    "\n",
    "Note: Full multimodal testing may require additional setup or model variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for medical image testing\n",
    "# This will be expanded once we have sample medical images\n",
    "\n",
    "print(\"Medical image testing planned for:\")\n",
    "print(\"- Chest X-ray interpretation\")\n",
    "print(\"- CT/MRI 3D volume analysis\")\n",
    "print(\"- Anatomical localization (bounding boxes)\")\n",
    "print(\"- Longitudinal imaging comparison\")\n",
    "print(\"\\nRequires: Sample medical imaging datasets (to be downloaded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Findings & Capabilities\n",
    "\n",
    "Document what MedGemma does well and limitations discovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings = {\n",
    "    \"strengths\": [\n",
    "        \"Clinical text understanding\",\n",
    "        \"Medical reasoning and differential diagnosis\",\n",
    "        \"Lab result interpretation\",\n",
    "        \"Medical Q&A and education\",\n",
    "        \"Small enough to run offline (4B params)\",\n",
    "        \"Fast inference (<10s typical)\"\n",
    "    ],\n",
    "    \"unique_capabilities\": [\n",
    "        \"3D CT/MRI interpretation\",\n",
    "        \"Longitudinal imaging analysis\",\n",
    "        \"Anatomical localization with bounding boxes\",\n",
    "        \"Whole-slide histopathology (WSI)\",\n",
    "        \"Multimodal (image + text) understanding\"\n",
    "    ],\n",
    "    \"limitations\": [\n",
    "        \"Requires validation for clinical use\",\n",
    "        \"May need specific prompt engineering\",\n",
    "        \"Performance varies by medical domain\",\n",
    "        \"Image testing requires additional setup\"\n",
    "    ],\n",
    "    \"performance\": {\n",
    "        \"inference_time\": f\"{avg_time:.2f}s average\",\n",
    "        \"model_size\": \"4B parameters\",\n",
    "        \"deployment\": \"Can run offline on modest hardware\"\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "print(json.dumps(findings, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "Based on testing, identify potential use cases for brainstorming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_steps = \"\"\"\n",
    "NEXT STEPS FOR DAYS 3-5:\n",
    "\n",
    "1. Download sample medical imaging datasets\n",
    "   - NIH Chest X-ray dataset (subset)\n",
    "   - Sample CT/MRI scans if available\n",
    "   - Clinical text datasets (MIMIC demo)\n",
    "\n",
    "2. Test multimodal capabilities\n",
    "   - Image + text interpretation\n",
    "   - Longitudinal analysis on sample data\n",
    "   - Anatomical localization testing\n",
    "\n",
    "3. Identify high-impact use cases\n",
    "   - What clinical problems can MedGemma uniquely solve?\n",
    "   - Where are the biggest gaps in current tools?\n",
    "   - What applications would judges find most impressive?\n",
    "\n",
    "4. Prepare for brainstorming (Days 6-10)\n",
    "   - Document MedGemma's competitive advantages\n",
    "   - Map capabilities to clinical pain points\n",
    "   - Create capability showcase examples\n",
    "\"\"\"\n",
    "\n",
    "print(next_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "MedGemma 1.5 4B shows strong capabilities in clinical text understanding and medical reasoning. The model is fast enough for real-time applications and small enough to deploy offline.\n",
    "\n",
    "**Key competitive advantages for hackathon:**\n",
    "1. First open model with 3D medical imaging support\n",
    "2. Longitudinal analysis capabilities (unique differentiator)\n",
    "3. Multimodal understanding (image + clinical context)\n",
    "4. Deployable size (4B params)\n",
    "\n",
    "These capabilities open up innovative use cases that weren't possible with previous models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
